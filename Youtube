import os
import googleapiclient.discovery
import requests
import json
from googleapiclient.discovery import build
import re
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from datetime import datetime, timedelta
import gspread
import pandas as pd
from googleapiclient.discovery import build
from google.oauth2.service_account import Credentials
from datetime import datetime
import schedule
import time
from gspread.exceptions import APIError
import isodate


def youtube_data_2(api_key, channel_id, first_worksheet):
    # def youtube_data_2(api_key, channel_id,worksheet1):
    def write_to_google_sheets(worksheet, data, index):
        try:
            worksheet.insert_row(data, index)
        except APIError as e:
            if e.response.status_code == 429:
                print("Quota exceeded. Waiting for 1 minute before retrying...")
                time.sleep(60)  # Затримка на 1 хвилину
                write_to_google_sheets(worksheet, data, index)  # Повторна спроба запису
            else:
                raise  # Перехоплюємо будь-які інші винятки
    
    
    # Загрузка учетных данных для доступа к Google Sheets API
    # Эти данные обычно предоставляются в виде файла JSON
    credentials = Credentials.from_service_account_file('credentials.json', scopes=['https://www.googleapis.com/auth/spreadsheets'])
    print("credentials успешная загрузка")
    
    # Создание объекта YouTube API
    youtube = build('youtube', 'v3', developerKey=api_key)
    
    # Создание объекта Google Sheets API
    sheets = build('sheets', 'v4', credentials=credentials)
    
    # Идентификатор вашей Google Таблицы
    SPREADSHEET_ID = '...'
    
    # Авторизація в Google Sheets
    gc = gspread.service_account(filename='credentials.json')
    # Відкриття Google документу за допомогою його ID
    spreadsheet = gc.open_by_key(SPREADSHEET_ID)
    
    # Функция для получения информации о видео, включая статистику
    def get_video_info(video_id):
        video_info = youtube.videos().list(part='snippet, statistics', id=video_id).execute()
        return video_info['items'][0]
    
    def get_video_duration(video_id):
        video_info = youtube.videos().list(part='contentDetails', id=video_id).execute()
        duration_iso = video_info['items'][0]['contentDetails']['duration']
        duration = isodate.parse_duration(duration_iso)
        duration_seconds = duration.total_seconds()
        formatted_duration = int(duration_seconds)
        return formatted_duration
    
    # Создание списка для данных
    data2 = []
    
    # Запрос на список відео з каналу
    channel_info = youtube.channels().list(part="contentDetails", id=channel_id).execute()
    playlist_id = channel_info['items'][0]['contentDetails']['relatedPlaylists']['uploads']
    
    next_page_token = None
    
    last_video_published_at = None
    
    while True:
        videos_info = youtube.playlistItems().list(part="snippet", playlistId=playlist_id, maxResults=50, pageToken=next_page_token).execute()
    
        for video in videos_info['items']:
            video_id = video['snippet']['resourceId']['videoId']
            video_published_at = datetime.strptime(video['snippet']['publishedAt'], '%Y-%m-%dT%H:%M:%SZ')
    
            # Проверяем, опубликовано ли видео за последние две недели
            if video_published_at >= datetime.now() - timedelta(weeks=2):
                last_video_published_at = video_published_at
                video_info = get_video_info(video_id)
                formatted_duration = get_video_duration(video_id)  # Отримуємо тривалість відео
                
                views = int(video_info['statistics'].get('viewCount', 0))
                likes = int(video_info['statistics'].get('likeCount', 0))
    
                data2.append({
                    'Назва': video['snippet']['title'],
                    'Канал': video['snippet']['channelTitle'],
                    'Посилання': f"https://www.youtube.com/watch?v={video_id}",
                    'Кількість переглядів': views,
                    'Лайки': likes,
                    'Тривалість, сек': formatted_duration,  # Змінено на formatted_duration
                    'Дата створення': video_published_at.strftime('%Y-%m-%d'),
                    'Дата додавання': datetime.today().strftime('%Y-%m-%d')
                })
            else:
                # Если видео не соответствует критериям, прерываем цикл
                break
    
        # Если дата последнего видео не соответствует критериям, прерываем цикл
        if last_video_published_at and last_video_published_at < datetime.now() - timedelta(weeks=2):
            break
    
        # Получение токена следующей страницы
        next_page_token = videos_info.get('nextPageToken')
    
        # Прерывание цикла, если нет следующей страницы
        if not next_page_token:
            break
    
    print("успешная загрузка Youtoube")
    
    
    worksheet = spreadsheet.worksheet(first_worksheet)
    existing_data_df3 = pd.DataFrame(worksheet.get_all_records())
    
    # Для 2 тижнів , 1М переглядів
    videos_over_million_views_two_week = [{**video, 'Коментарі': '2weeks'} for video in data2 if video['Кількість переглядів'] > 1000000]
    help_two_week=pd.DataFrame(videos_over_million_views_two_week)
    if not help_two_week.empty:
        new_data_help3 = help_two_week.merge(existing_data_df3[['Назва', 'Дата створення']], indicator=True, how='left').loc[lambda x: x['_merge'] == 'left_only'].drop(columns='_merge')
        # Збереження нових даних в Google документ
        for i, row in enumerate(new_data_help3.values):
            write_to_google_sheets(worksheet, row.tolist(), i+2)
        print("Two weeks - goooo!")
    else:
        print("DataFrame help_two_week is empty. No new data to process.")
    
    # Для 3х днів , 100к переглядів
    # Визначення дати, яка відповідає 3 дням назад
    three_days_ago = datetime.now() - timedelta(days=3)
    # Відбір відео за останні 3 дні
    three_days_videos = [video for video in data2 if video['Дата створення'] >= three_days_ago.strftime('%Y-%m-%d')]
    # Обчислення кількості відео з кількістю переглядів більше 20 000 та додавання колонки "Коментарі"
    videos_over_million_views_three_days = [{**video, 'Коментарі': '3days'} for video in three_days_videos if video['Кількість переглядів'] > 100000]
    help_tree_day=pd.DataFrame(videos_over_million_views_three_days)
    if not help_tree_day.empty:
        # Читання існуючих даних з Google Sheets
        new_data_help4 = help_tree_day.merge(existing_data_df3[['Назва', 'Дата створення']], indicator=True, how='left').loc[lambda x: x['_merge'] == 'left_only'].drop(columns='_merge')
        # Збереження нових даних в Google документ
        for i, row in enumerate(new_data_help4.values):
            write_to_google_sheets(worksheet, row.tolist(), i+2)
        print("Tree days - goooo!")
    else:
        print("DataFrame help_tree_day  is empty. No new data to process.")



def job_123():
    channel_ids = ["ChannelApi1","ChannelApi2","ChannelApi3",...]
    
    for idx, channel_id in enumerate(channel_ids):
        youtube_data_2("ApiGoogleCloud1", channel_id, "Sheet1")
        print(f"Канал {idx + 1}/{len(channel_ids)} успішно завершено")
        print("-"*20)
    print("Усі канали оброблені")

def job_YB_1():
    channel_ids = ["ChannelApi7","ChannelApi8","ChannelApi9",...]


    for idx, channel_id in enumerate(channel_ids):
        youtube_data_2("ApiGoogleCloud2", channel_id, "Sheet2")
        print(f"Канал {idx + 1}/{len(channel_ids)} успішно завершено")
        print("-"*20)
    print("Усі канали оброблені")
    
# Запуск функции `job_123` каждый день в 12:00
schedule.every().day.at("09:40").do(job_123)


# Запуск функции `job_YB_1` каждый день в 12:00
schedule.every().day.at("10:00").do(job_YB_1)


while True:
    schedule.run_pending()
    time.sleep(1)
